{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1HVX4oH-YDuAv8PW7oePocO5-_FCh3y30",
      "authorship_tag": "ABX9TyOnzuqT5oO5dJ06fNxpfP0Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fathursidiq/CNNtampalibrary/blob/main/Unsupervised_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras import layers, models, optimizers, losses\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.signal import hilbert\n",
        "from scipy.signal import welch\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "LeEiowblLZYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_and_target_from_folder(data_folder_path, target_folder_path, delimiter=';'):\n",
        "    data_files = glob.glob(os.path.join(data_folder_path, '*.CSV'))\n",
        "    data_files.sort()\n",
        "    data_list = []\n",
        "    target_list = []\n",
        "    target2_list = []\n",
        "    for data_file in data_files:\n",
        "        file_name = os.path.splitext(os.path.basename(data_file))[0]\n",
        "        target_file = os.path.join(target_folder_path, f'{file_name}.CSV')\n",
        "        if os.path.exists(target_file):\n",
        "            df_data = pd.read_csv(data_file, delimiter=delimiter)[1000:9000]\n",
        "            df_target = pd.read_csv(target_file, delimiter=delimiter)[1000:9000]\n",
        "            data_list.append(df_data.filter(like='data').values)\n",
        "            target_list.append(df_target.filter(like='pwave').values)\n",
        "            target2_list.append(df_target.filter(like='swave').values)\n",
        "    data_array = np.concatenate(data_list)\n",
        "    target_array = np.concatenate(target_list)\n",
        "    target2_array = np.concatenate(target2_list)\n",
        "    return data_array, target_array, target2_array\n",
        "data_folder_path = '/content/drive/MyDrive/thesis/filtered'\n",
        "target_folder_path = '/content/drive/MyDrive/thesis/label'\n",
        "data_array, target_array, target2_array = load_data_and_target_from_folder(data_folder_path, target_folder_path)"
      ],
      "metadata": {
        "id": "1WbyMIc9LfN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussLegendreQuadrature:\n",
        "    def __init__(self, num_points=3):\n",
        "        self.num_points = num_points\n",
        "        self.points, self.weights = np.polynomial.legendre.leggauss(num_points)\n",
        "\n",
        "    def integrate(self, function):\n",
        "        result = np.sum(self.weights * function(self.points))\n",
        "        return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    def function_to_integrate(x):\n",
        "        return x\n",
        "    num_points = 4\n",
        "    gauss_legendre = GaussLegendreQuadrature(num_points)\n",
        "    x_vals = np.array(data_array)[100000:400000]\n",
        "    cumulative_results = []\n",
        "    cumulative_sum = 0\n",
        "    for x in x_vals:\n",
        "        cumulative_sum += gauss_legendre.integrate(lambda x_val: function_to_integrate(x_val + x))\n",
        "        cumulative_results.append(cumulative_sum)\n",
        "\n",
        "    analytic_signal = hilbert(cumulative_results)\n",
        "    hilbert_gauss_legendre = np.abs(analytic_signal)\n",
        "    analytic_s = hilbert(x_vals)\n",
        "    hilbert_envelope = np.abs(analytic_s)\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(4, 1, 1)\n",
        "    plt.plot(x_vals, label='Original Sine Wave')\n",
        "    plt.title('Original Sine Wave Function')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "    plt.subplot(4, 1, 2)\n",
        "    plt.plot( np.array(cumulative_results), label='Cumulative Integration ', color='orange')\n",
        "    plt.title('Cumulative Integration of Sine Wave using Gaussian-Legendre Quadrature')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('Cumulative Amplitude')\n",
        "    plt.legend()\n",
        "    plt.subplot(4, 1, 3)\n",
        "    plt.plot( hilbert_gauss_legendre, label='Hilbert_Gauss Transform Analysis', color='green')\n",
        "    plt.title('Hilbert Transform Analysis')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "    plt.subplot(4, 1, 4)\n",
        "    plt.plot( hilbert_envelope, label='Hilbert Transform Analysis', color='green')\n",
        "    plt.title('Hilbert Transform Analysis')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YOGXss08x3rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bZ-xGSVKoTv"
      },
      "outputs": [],
      "source": [
        "data = np.array(hilbert_gauss_legendre)\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "data = scaler.fit_transform(data.reshape(-1, 1)).flatten()\n",
        "input_signal = data.reshape(1, -1, 1)  # Shape: (1, len(data), 1)\n",
        "\n",
        "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return 1 - (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def create_model(input_shape, num_heads=4):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Encoder\n",
        "    x = layers.Conv1D(32, 3, padding='same', activation='relu')(inputs)\n",
        "    x = layers.MaxPooling1D(2)(x)\n",
        "    x = layers.Conv1D(8, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling1D(2)(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "    # Multi-Head Attention\n",
        "    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=128)(x, x)\n",
        "    # Decoder\n",
        "    x = layers.Bidirectional(layers.LSTM(8, return_sequences=True))(attn_output)\n",
        "    x = layers.Conv1DTranspose(8, 2, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.Conv1DTranspose(1, 2, strides=2, padding='same', activation='sigmoid')(x)\n",
        "    # Output layer for binary classification\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inputs, x)\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=dice_loss)\n",
        "    return model\n",
        "\n",
        "\n",
        "input_shape = (input_signal.shape[1], input_signal.shape[2])\n",
        "model = create_model(input_shape)\n",
        "model.summary()\n",
        "target_signal = np.random.randint(0, 2, size=(1, input_signal.shape[1], 1)).astype(float)\n",
        "history = model.fit(input_signal, target_signal, epochs=50, batch_size=1, verbose=1)\n",
        "model.save('/content/drive/MyDrive/thesis/model_unsupervised/conv_bilstm_autoencoder_with_attention.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.load_model('conv_bilstm_autoencoder_with_attention.h5', custom_objects={'dice_loss': dice_loss})\n",
        "predictions = model.predict(input_signal).squeeze()\n",
        "binary_predictions = (predictions > 0.5).astype(int).flatten()\n",
        "y_true = target_signal.flatten()\n",
        "y_pred = binary_predictions\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1']))\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=['Class 0', 'Class 1'])\n"
      ],
      "metadata": {
        "id": "eoHITJTfLJWI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}